{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 190 Final Project - Predicting the Result of the League of Legends games based on the champion composition and team statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### by Tat Hei Tsin and Dennis Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "League of Legends (LoL) is a 5v5 games with players choosing different champions to combat the enemy team. There are over a hundred champions for the players to choose, and different combination will render As huge LoL fans, we wonder what are the important factors that can determine the result of the LoL games. Firstly, we parse the data of Riot Api to build the baseline model to get a sense of the features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have gathered our data from three different sites. The first option we did was scraping data from Riot API (Company that developed League of legends): \\url{https://developer.riotgames.com}. However, we encountered a lot of problems in obtaining data due to strict regulation of number of requests per second, and we only gathered around 1000 instances till data. Therefore, we set eyes on other publicly available data sets. The second option we chose was a high elo players (High performance players in ranked games) data set from Kaggle: \\url{https://www.kaggle.com/gyejr95/league-of-legends-challenger-ranked-games2020}. This data set consists over 200,000 games from the highest level of competition. The following Exploratory Data Analysis (EDA) would be done with this data set. For the third option, we found a data set consists of all the competitive matches recorded along the years: \\url{https://oracleselixir.com/matchdata/}. There are different upsides and downsides regarding the three data sets. For option 1, we are able to get the richest data by far, but the distribution of the matches might be biased since we collected the player IDs according to their levels. For Option 2, that data set has the largest number of matches recorded among all the data sets, but the data set contains the least information per match among all the data sets. For the third option, the data set contains a decent number of matches and with more preprocessed details readily available. We decided to work on data set option 2.\n",
    "\n",
    "We did our exploratory data analysis with the 26,000 challenger games in option 2. We implemented preprocessing steps to the data set since for one instance, the data set contains information for both teams. Therefore, we divided the instance into the red team/ blue teams, adding our instance to 52,000 instances in total. We listed the basic statistics of all the parameter in figure 2. All the parameters in the model are type int64, except Avglevel (float64). There are six categorical parameters which describe important objective in the game. After looking into the data, we are more interested in understanding what are the crucial factors that determines a win or a loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this predictive task, we hope to find out more about the weight off different factors in predicting a win / loss to a game. We plan to use a variety of models to tackle this classification problem: logistic regression and XGBoost. \n",
    "We have all our end-game statistics provided in the data set, our baseline model would be logistic regression since we have a binary outcome: win/ lose. Moreover, and we make the assumption that all the statistics are a linear combination towards the end result. However, to further amplify our model, we utilize the XGBoost classifier in the refined model to increase the accuracy of our model, because boosted trees can largely increase the prediction power with gradient boosted decision trees that could iteratively refine the model. To evaluate the model(s), we would be using two metrics: Accuracy and F1 score. We choose accuracy since we would like to know how well the model predicts wins/ loses. F1 score would also be another comprehensive evaluation metric since it would give us an insight to the recall and precision of the model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data without parsing (high ranked players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_games = pd.read_csv(\"data/Challenger_Ranked_Games.csv\")\n",
    "grandmaster_games = pd.read_csv(\"data/GrandMaster_Ranked_Games.csv\")\n",
    "master_games = pd.read_csv(\"data/Master_Ranked_Games.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the basedline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the usernames from the requests and BeautifulSoup in a website with a list of summoner names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://lolnames.gg/en/highscores/na/1000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summoners = soup.findAll(\"td\", {\"class\": \"align-middle h5\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for summoner in summoners:\n",
    "    names.append(summoner.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blueberry Dango',\n",
       " 'NyxWulf',\n",
       " 'Yi Gè Rén',\n",
       " 'BlaoThorne RJ',\n",
       " 'IPMagazine ',\n",
       " 'Ewokcore',\n",
       " 'A Legendary Crab',\n",
       " 'MelroseR',\n",
       " 'UwU BigStrongMan',\n",
       " 'PÊÑNŸWÏŠË']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreive the match by getting the most recent ten games of each user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the data are the most active users in North American server, we deem that the most recent ten games will provide us with the up to date data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_id = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Riot Api Watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "key = 'RGAPI-2e8bb194-790e-4c82-89a7-8336b64f9bfc'\n",
    "watcher = LolWatcher(key)\n",
    "my_region = 'na1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://na1.api.riotgames.com/lol/summoner/v4/summoners/by-name/Blueberry%20Dango",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\riotwatcher\\Handlers\\ThrowOnErrorHandler.py\u001b[0m in \u001b[0;36mafter_request\u001b[1;34m(self, region, endpoint_name, method_name, url, response)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://na1.api.riotgames.com/lol/summoner/v4/summoners/by-name/Blueberry%20Dango",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ddf61f207951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_match_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummoner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mby_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_region\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmy_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatchlist_by_account\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_region\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mme\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accountId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\riotwatcher\\_apis\\league_of_legends\\SummonerApiV4.py\u001b[0m in \u001b[0;36mby_name\u001b[1;34m(self, region, summoner_name)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mregion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mSummonerApiV4Urls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mby_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0msummoner_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msummoner_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         )\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\riotwatcher\\_apis\\NamedEndpoint.py\u001b[0m in \u001b[0;36m_request_endpoint\u001b[1;34m(self, method_name, region, endpoint, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         return self._base_api.raw_request(\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_endpoint_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\riotwatcher\\_apis\\BaseApi.py\u001b[0m in \u001b[0;36mraw_request\u001b[1;34m(self, endpoint_name, method_name, region, url, query_params)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request_handlers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_ret_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 mod = handler.after_request(\n\u001b[1;32m---> 51\u001b[1;33m                     \u001b[0mregion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 )\n\u001b[0;32m     53\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\riotwatcher\\Handlers\\ThrowOnErrorHandler.py\u001b[0m in \u001b[0;36mafter_request\u001b[1;34m(self, region, endpoint_name, method_name, url, response)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mApiError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://na1.api.riotgames.com/lol/summoner/v4/summoners/by-name/Blueberry%20Dango"
     ]
    }
   ],
   "source": [
    "test_match_id = []\n",
    "for pid in test:\n",
    "    me = watcher.summoner.by_name(my_region, pid)\n",
    "    my_matches = watcher.match.matchlist_by_account(my_region, me['accountId'])\n",
    "    for i in range(10):\n",
    "        test_match_id.append(my_matches[\"matches\"][i]['gameId'])\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_match_id = [3450551207,\n",
    " 3450447940,\n",
    " 3450473349,\n",
    " 3449910866,\n",
    " 3449809573,\n",
    " 3449805002,\n",
    " 3449395985,\n",
    " 3449420612,\n",
    " 3449368014,\n",
    " 3448536602,\n",
    " 3409538636,\n",
    " 3409524617,\n",
    " 3409469635,\n",
    " 3409444191,\n",
    " 3406092238,\n",
    " 3406038402,\n",
    " 3406044245,\n",
    " 3405683989,\n",
    " 3449415869,\n",
    " 3449391063,\n",
    " 3449327412,\n",
    " 3449314380,\n",
    " 3450473349,\n",
    " 3450384967,\n",
    " 3449941896,\n",
    " 3449917039,\n",
    " 3449911789,\n",
    " 3449857306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check league's latest version\n",
    "latest = watcher.data_dragon.versions_for_region(my_region)['n']['champion']\n",
    "# Lets get some champions static information\n",
    "static_champ_list = watcher.data_dragon.champions(latest, False, 'en_US')\n",
    "\n",
    "# champ static list data to dict for looking up\n",
    "champ_dict = {}\n",
    "for key in static_champ_list['data']:\n",
    "    row = static_champ_list['data'][key]\n",
    "    champ_dict[row['key']] = row['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'266': 'Aatrox',\n",
       " '103': 'Ahri',\n",
       " '84': 'Akali',\n",
       " '12': 'Alistar',\n",
       " '32': 'Amumu',\n",
       " '34': 'Anivia',\n",
       " '1': 'Annie',\n",
       " '523': 'Aphelios',\n",
       " '22': 'Ashe',\n",
       " '136': 'AurelionSol',\n",
       " '268': 'Azir',\n",
       " '432': 'Bard',\n",
       " '53': 'Blitzcrank',\n",
       " '63': 'Brand',\n",
       " '201': 'Braum',\n",
       " '51': 'Caitlyn',\n",
       " '164': 'Camille',\n",
       " '69': 'Cassiopeia',\n",
       " '31': 'Chogath',\n",
       " '42': 'Corki',\n",
       " '122': 'Darius',\n",
       " '131': 'Diana',\n",
       " '119': 'Draven',\n",
       " '36': 'DrMundo',\n",
       " '245': 'Ekko',\n",
       " '60': 'Elise',\n",
       " '28': 'Evelynn',\n",
       " '81': 'Ezreal',\n",
       " '9': 'Fiddlesticks',\n",
       " '114': 'Fiora',\n",
       " '105': 'Fizz',\n",
       " '3': 'Galio',\n",
       " '41': 'Gangplank',\n",
       " '86': 'Garen',\n",
       " '150': 'Gnar',\n",
       " '79': 'Gragas',\n",
       " '104': 'Graves',\n",
       " '120': 'Hecarim',\n",
       " '74': 'Heimerdinger',\n",
       " '420': 'Illaoi',\n",
       " '39': 'Irelia',\n",
       " '427': 'Ivern',\n",
       " '40': 'Janna',\n",
       " '59': 'JarvanIV',\n",
       " '24': 'Jax',\n",
       " '126': 'Jayce',\n",
       " '202': 'Jhin',\n",
       " '222': 'Jinx',\n",
       " '145': 'Kaisa',\n",
       " '429': 'Kalista',\n",
       " '43': 'Karma',\n",
       " '30': 'Karthus',\n",
       " '38': 'Kassadin',\n",
       " '55': 'Katarina',\n",
       " '10': 'Kayle',\n",
       " '141': 'Kayn',\n",
       " '85': 'Kennen',\n",
       " '121': 'Khazix',\n",
       " '203': 'Kindred',\n",
       " '240': 'Kled',\n",
       " '96': 'KogMaw',\n",
       " '7': 'Leblanc',\n",
       " '64': 'LeeSin',\n",
       " '89': 'Leona',\n",
       " '127': 'Lissandra',\n",
       " '236': 'Lucian',\n",
       " '117': 'Lulu',\n",
       " '99': 'Lux',\n",
       " '54': 'Malphite',\n",
       " '90': 'Malzahar',\n",
       " '57': 'Maokai',\n",
       " '11': 'MasterYi',\n",
       " '21': 'MissFortune',\n",
       " '62': 'MonkeyKing',\n",
       " '82': 'Mordekaiser',\n",
       " '25': 'Morgana',\n",
       " '267': 'Nami',\n",
       " '75': 'Nasus',\n",
       " '111': 'Nautilus',\n",
       " '518': 'Neeko',\n",
       " '76': 'Nidalee',\n",
       " '56': 'Nocturne',\n",
       " '20': 'Nunu',\n",
       " '2': 'Olaf',\n",
       " '61': 'Orianna',\n",
       " '516': 'Ornn',\n",
       " '80': 'Pantheon',\n",
       " '78': 'Poppy',\n",
       " '555': 'Pyke',\n",
       " '246': 'Qiyana',\n",
       " '133': 'Quinn',\n",
       " '497': 'Rakan',\n",
       " '33': 'Rammus',\n",
       " '421': 'RekSai',\n",
       " '58': 'Renekton',\n",
       " '107': 'Rengar',\n",
       " '92': 'Riven',\n",
       " '68': 'Rumble',\n",
       " '13': 'Ryze',\n",
       " '113': 'Sejuani',\n",
       " '235': 'Senna',\n",
       " '875': 'Sett',\n",
       " '35': 'Shaco',\n",
       " '98': 'Shen',\n",
       " '102': 'Shyvana',\n",
       " '27': 'Singed',\n",
       " '14': 'Sion',\n",
       " '15': 'Sivir',\n",
       " '72': 'Skarner',\n",
       " '37': 'Sona',\n",
       " '16': 'Soraka',\n",
       " '50': 'Swain',\n",
       " '517': 'Sylas',\n",
       " '134': 'Syndra',\n",
       " '223': 'TahmKench',\n",
       " '163': 'Taliyah',\n",
       " '91': 'Talon',\n",
       " '44': 'Taric',\n",
       " '17': 'Teemo',\n",
       " '412': 'Thresh',\n",
       " '18': 'Tristana',\n",
       " '48': 'Trundle',\n",
       " '23': 'Tryndamere',\n",
       " '4': 'TwistedFate',\n",
       " '29': 'Twitch',\n",
       " '77': 'Udyr',\n",
       " '6': 'Urgot',\n",
       " '110': 'Varus',\n",
       " '67': 'Vayne',\n",
       " '45': 'Veigar',\n",
       " '161': 'Velkoz',\n",
       " '254': 'Vi',\n",
       " '112': 'Viktor',\n",
       " '8': 'Vladimir',\n",
       " '106': 'Volibear',\n",
       " '19': 'Warwick',\n",
       " '498': 'Xayah',\n",
       " '101': 'Xerath',\n",
       " '5': 'XinZhao',\n",
       " '157': 'Yasuo',\n",
       " '83': 'Yorick',\n",
       " '350': 'Yuumi',\n",
       " '154': 'Zac',\n",
       " '238': 'Zed',\n",
       " '115': 'Ziggs',\n",
       " '26': 'Zilean',\n",
       " '142': 'Zoe',\n",
       " '143': 'Zyra'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champ_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the champion score from www.metasrc.com, create a DataFrame of the champions with their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>champion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>champion_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Aatrox</td>\n",
       "      <td>48.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Ahri</td>\n",
       "      <td>61.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Akali</td>\n",
       "      <td>37.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alistar</td>\n",
       "      <td>51.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Amumu</td>\n",
       "      <td>51.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Zed</td>\n",
       "      <td>66.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Ziggs</td>\n",
       "      <td>40.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Zilean</td>\n",
       "      <td>47.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Zoe</td>\n",
       "      <td>51.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Zyra</td>\n",
       "      <td>49.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            champion   score\n",
       "champion_id                 \n",
       "266           Aatrox  48.605\n",
       "103             Ahri  61.970\n",
       "84             Akali  37.425\n",
       "12           Alistar  51.010\n",
       "32             Amumu  51.170\n",
       "...              ...     ...\n",
       "238              Zed  66.880\n",
       "115            Ziggs  40.660\n",
       "26            Zilean  47.315\n",
       "142              Zoe  51.960\n",
       "143             Zyra  49.460\n",
       "\n",
       "[148 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping individual champion score\n",
    "r1 = requests.get(\"https://www.metasrc.com/5v5/na/tierlist\")\n",
    "soup1 = BeautifulSoup(r1.text, \"html.parser\")\n",
    "power_level = soup1.findAll(\"div\", {\"class\": \"_9581uw\"})\n",
    "names = soup1.findAll(\"div\", {\"class\": \"_q8ue62\"})\n",
    "champ = []\n",
    "for name in names:\n",
    "    champ.append(name.getText())\n",
    "rates = []\n",
    "for rate in power_level:\n",
    "    rates.append(rate.getText())\n",
    "tierlist = pd.DataFrame().assign(\n",
    "    champ = champ,\n",
    "    score = rates\n",
    ")\n",
    "tierlist.sort_values(by = [\"champ\"])\n",
    "\n",
    "# Getting individual Champion IDs\n",
    "IDs = pd.read_csv(\"data/new.txt\", sep = \":\", header = None)\n",
    "IDs.columns = [\"ID\", \"champ\"]\n",
    "\n",
    "champion_list = tierlist.sort_values(by = [\"champ\"])[\"champ\"].unique()\n",
    "\n",
    "# Merging Ids and individual champion score\n",
    "new_tierlist = []\n",
    "\n",
    "# Averaging similar champions scores into one\n",
    "for champ in champion_list:\n",
    "    row = {}\n",
    "    champ_list = tierlist[tierlist[\"champ\"] == champ]\n",
    "    champ_list_avg = champ_list[\"score\"].astype(float).mean()\n",
    "    row[\"champ\"] = champ\n",
    "    row[\"score\"] = champ_list_avg\n",
    "    new_tierlist.append(row)\n",
    "\n",
    "tierlist_pd = pd.DataFrame(new_tierlist)\n",
    "tierlist_pd = tierlist_pd.sort_values(by = [\"champ\"])\n",
    "champion_score = IDs.merge(tierlist_pd, on = champion_list)\n",
    "champion_score = champion_score.drop(columns = [\"champ_x\", \"champ_y\"])\n",
    "champion_score.columns = [\"champion\", \"champion_id\", \"score\"]\n",
    "champion_score = champion_score.set_index([\"champion_id\"])\n",
    "\n",
    "champion_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the input matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matches = []\n",
    "\n",
    "for ID in test_match_id:\n",
    "    match_info = watcher.match.by_id(my_region, ID)\n",
    "    input_matches.append(match_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the match data to a DataFrame of useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matchID to matches\n",
    "\n",
    "# Inputting data frame\n",
    "output_detail = []\n",
    "y_result = []\n",
    "\n",
    "difference_list = [\"totalMinionsKilled\", \"longestTimeSpentLiving\", \"totalHeal\", \"totalDamageDealt\", \"magicDamageDealt\", \"physicalDamageDealt\", \"totalDamageDealtToChampions\", \"magicDamageDealtToChampions\", \"trueDamageDealtToChampions\", \"goldEarned\"]\n",
    "tower_list = [\"towerKills\", \"inhibitorKills\", \"riftHeraldKills\"]\n",
    "\n",
    "#Creating individual player scores\n",
    "for match_detail in input_matches:\n",
    "    participants = []\n",
    "    team = []\n",
    "    scores = []\n",
    "    \n",
    "#     print(match_detail[\"gameMode\"])\n",
    "    # Calculate Individual statistics\n",
    "    for row in match_detail['participants']:\n",
    "        participants_row = {}\n",
    "        participants_row['champion_Id'] = row['championId']\n",
    "        participants_row['team'] = row['teamId']\n",
    "        participants_row['kills'] = row['stats']['kills']\n",
    "        participants_row['deaths'] = row['stats']['deaths']\n",
    "        participants_row['assists'] = row['stats']['assists']\n",
    "        participants_row['totalDamageDealt'] = row['stats']['totalDamageDealt']\n",
    "        participants_row['magicDamageDealt'] = row['stats']['magicDamageDealt']\n",
    "        participants_row['physicalDamageDealt'] = row['stats']['physicalDamageDealt']\n",
    "        participants_row['physicalDamageDealt'] = row['stats']['physicalDamageDealt']\n",
    "        participants_row['totalDamageDealtToChampions'] = row['stats']['totalDamageDealtToChampions']\n",
    "        participants_row['magicDamageDealtToChampions'] = row['stats']['magicDamageDealtToChampions']\n",
    "        participants_row['physicalDamageDealtToChampions'] = row['stats']['physicalDamageDealtToChampions']\n",
    "        participants_row['trueDamageDealtToChampions'] = row['stats']['trueDamageDealtToChampions']    \n",
    "        participants_row['goldEarned'] = row['stats']['goldEarned']\n",
    "        participants_row['champLevel'] = row['stats']['champLevel'] / 18\n",
    "        participants_row['totalMinionsKilled'] = row['stats']['totalMinionsKilled']\n",
    "        participants_row['largestMultiKill'] = row['stats']['largestMultiKill']\n",
    "        participants_row['killingSprees'] = row['stats']['killingSprees']\n",
    "        participants_row['doubleKills'] = row['stats']['doubleKills']\n",
    "        participants_row['tripleKills'] = row['stats']['tripleKills']\n",
    "        participants_row['quadraKills'] = row['stats']['quadraKills']\n",
    "        participants_row['pentaKills'] = row['stats']['pentaKills']\n",
    "        participants_row['longestTimeSpentLiving'] = row['stats']['longestTimeSpentLiving']\n",
    "        participants_row['totalHeal'] = row['stats']['totalHeal']\n",
    "        participants_row['damageDealtToObjectives'] = row['stats']['damageDealtToObjectives']\n",
    "        participants_row['damageDealtToObjectives'] = row['stats']['damageDealtToObjectives']\n",
    "        participants_row['damageDealtToTurrets'] = row['stats']['damageDealtToTurrets']\n",
    "        participants_row['visionScore'] = row['stats']['visionScore']\n",
    "        participants_row['timeCCingOthers'] = row['stats']['timeCCingOthers']\n",
    "        participants_row['totalDamageTaken'] = row['stats']['totalDamageTaken']\n",
    "        participants_row['magicalDamageTaken'] = row['stats']['magicalDamageTaken']\n",
    "        participants_row['physicalDamageTaken'] = row['stats']['physicalDamageTaken']   \n",
    "        participants_row['trueDamageTaken'] = row['stats']['trueDamageTaken']   \n",
    "        participants.append(participants_row)\n",
    "\n",
    "    # Champion scores conversion\n",
    "    match = pd.DataFrame(participants)\n",
    "    champions = match[\"champion_Id\"]\n",
    "    for champ in champions:\n",
    "        scores.append(champion_score.loc[champ].get(\"score\"))\n",
    "    scores_pd = pd.DataFrame(scores)\n",
    "    scores_pd.columns = [\"score\"]\n",
    "    match = match.join(scores_pd)\n",
    "    grouped = match.groupby([\"team\"]).sum()\n",
    "    grouped = grouped.drop(columns = ['champion_Id'])\n",
    "        \n",
    "    # Calculate Team statistsics\n",
    "    for row in match_detail['teams']:\n",
    "        team_row = {}\n",
    "        team_row['team'] = row['teamId']\n",
    "        team_row['firstBlood'] = int(row['firstBlood'] == True)\n",
    "        team_row['firstTower'] = int(row['firstTower'] == True)\n",
    "        team_row['firstBaron'] = int(row['firstBaron'] == True)\n",
    "        team_row['firstDragon'] = int(row['firstDragon'] == True)\n",
    "        team_row['firstBlood'] = int(row['firstBlood'] == True) \n",
    "        team_row['firstRiftHerald'] = int(row['firstRiftHerald'] == True)\n",
    "        team_row['towerKills'] = row['towerKills'] / 11\n",
    "        team_row['inhibitorKills'] = row['inhibitorKills'] / 3\n",
    "        team_row['baronKills'] = row['baronKills'] \n",
    "        team_row['dragonKills'] = row['dragonKills']    \n",
    "        team_row['riftHeraldKills'] = row['riftHeraldKills'] / 2\n",
    "        result = row[\"win\"]\n",
    "        if (result == \"Win\"):\n",
    "            y_result.append(\"1\")\n",
    "        elif (result == \"Fail\"):\n",
    "            y_result.append(\"0\")\n",
    "        team.append(team_row)\n",
    "\n",
    "    team_df = pd.DataFrame(team)\n",
    "    final_df = team_df.merge(grouped, on = \"team\")\n",
    "    final_df = final_df.drop(columns = [\"team\"])\n",
    "    #print(final_df)\n",
    "\n",
    "    #for column in difference_list:\n",
    "        \n",
    "    #break;\n",
    "    for index, row in final_df.iterrows():\n",
    "        output_detail.append(pd.DataFrame(row).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in output_detail:\n",
    "    df = pd.concat([df, i])\n",
    "    \n",
    "df[\"result\"] = pd.Series(y_result).astype(int)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstBlood</th>\n",
       "      <th>firstTower</th>\n",
       "      <th>firstBaron</th>\n",
       "      <th>firstDragon</th>\n",
       "      <th>firstRiftHerald</th>\n",
       "      <th>towerKills</th>\n",
       "      <th>inhibitorKills</th>\n",
       "      <th>baronKills</th>\n",
       "      <th>dragonKills</th>\n",
       "      <th>riftHeraldKills</th>\n",
       "      <th>...</th>\n",
       "      <th>damageDealtToObjectives</th>\n",
       "      <th>damageDealtToTurrets</th>\n",
       "      <th>visionScore</th>\n",
       "      <th>timeCCingOthers</th>\n",
       "      <th>totalDamageTaken</th>\n",
       "      <th>magicalDamageTaken</th>\n",
       "      <th>physicalDamageTaken</th>\n",
       "      <th>trueDamageTaken</th>\n",
       "      <th>score</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>6689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>86579.0</td>\n",
       "      <td>16083.0</td>\n",
       "      <td>66466.0</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>328.480000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>87404.0</td>\n",
       "      <td>36836.0</td>\n",
       "      <td>37295.0</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>231.865000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7822.0</td>\n",
       "      <td>7822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>228220.0</td>\n",
       "      <td>99974.0</td>\n",
       "      <td>121880.0</td>\n",
       "      <td>6361.0</td>\n",
       "      <td>254.345000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>198056.0</td>\n",
       "      <td>57551.0</td>\n",
       "      <td>118924.0</td>\n",
       "      <td>21576.0</td>\n",
       "      <td>247.645000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7594.0</td>\n",
       "      <td>7594.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>188143.0</td>\n",
       "      <td>124481.0</td>\n",
       "      <td>48609.0</td>\n",
       "      <td>15048.0</td>\n",
       "      <td>247.233333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5217.0</td>\n",
       "      <td>5217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>155030.0</td>\n",
       "      <td>73761.0</td>\n",
       "      <td>69116.0</td>\n",
       "      <td>12148.0</td>\n",
       "      <td>242.855000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68631.0</td>\n",
       "      <td>30414.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>157206.0</td>\n",
       "      <td>99249.0</td>\n",
       "      <td>53627.0</td>\n",
       "      <td>4324.0</td>\n",
       "      <td>263.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94279.0</td>\n",
       "      <td>30962.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>162145.0</td>\n",
       "      <td>71013.0</td>\n",
       "      <td>86223.0</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>252.873333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27439.0</td>\n",
       "      <td>10077.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>85258.0</td>\n",
       "      <td>43306.0</td>\n",
       "      <td>27703.0</td>\n",
       "      <td>14244.0</td>\n",
       "      <td>312.210000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89484.0</td>\n",
       "      <td>37200.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>108166.0</td>\n",
       "      <td>30057.0</td>\n",
       "      <td>68603.0</td>\n",
       "      <td>9501.0</td>\n",
       "      <td>272.885000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90236.0</td>\n",
       "      <td>33923.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>237405.0</td>\n",
       "      <td>135469.0</td>\n",
       "      <td>81444.0</td>\n",
       "      <td>20488.0</td>\n",
       "      <td>276.070000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116608.0</td>\n",
       "      <td>32281.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>287111.0</td>\n",
       "      <td>69924.0</td>\n",
       "      <td>190708.0</td>\n",
       "      <td>26473.0</td>\n",
       "      <td>316.820000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9754.0</td>\n",
       "      <td>9754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>94899.0</td>\n",
       "      <td>47450.0</td>\n",
       "      <td>34028.0</td>\n",
       "      <td>13415.0</td>\n",
       "      <td>254.660000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>76870.0</td>\n",
       "      <td>13122.0</td>\n",
       "      <td>57832.0</td>\n",
       "      <td>5911.0</td>\n",
       "      <td>251.110000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>161242.0</td>\n",
       "      <td>135728.0</td>\n",
       "      <td>20024.0</td>\n",
       "      <td>5485.0</td>\n",
       "      <td>257.430000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12681.0</td>\n",
       "      <td>12681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>159968.0</td>\n",
       "      <td>105181.0</td>\n",
       "      <td>52795.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>280.710000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70754.0</td>\n",
       "      <td>25808.0</td>\n",
       "      <td>38363.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>316.825000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90250.0</td>\n",
       "      <td>35184.0</td>\n",
       "      <td>51932.0</td>\n",
       "      <td>3129.0</td>\n",
       "      <td>234.050000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51911.0</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>111378.0</td>\n",
       "      <td>45574.0</td>\n",
       "      <td>61803.0</td>\n",
       "      <td>3994.0</td>\n",
       "      <td>349.360000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59135.0</td>\n",
       "      <td>19586.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93089.0</td>\n",
       "      <td>18096.0</td>\n",
       "      <td>66912.0</td>\n",
       "      <td>8074.0</td>\n",
       "      <td>268.496667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8999.0</td>\n",
       "      <td>8999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>99805.0</td>\n",
       "      <td>76944.0</td>\n",
       "      <td>17007.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>278.970000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>111973.0</td>\n",
       "      <td>51608.0</td>\n",
       "      <td>54423.0</td>\n",
       "      <td>5938.0</td>\n",
       "      <td>245.315000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9782.0</td>\n",
       "      <td>9782.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>214156.0</td>\n",
       "      <td>93044.0</td>\n",
       "      <td>103956.0</td>\n",
       "      <td>17151.0</td>\n",
       "      <td>234.945000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5416.0</td>\n",
       "      <td>5416.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>177257.0</td>\n",
       "      <td>124601.0</td>\n",
       "      <td>48434.0</td>\n",
       "      <td>4218.0</td>\n",
       "      <td>292.935000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10757.0</td>\n",
       "      <td>10757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>174813.0</td>\n",
       "      <td>35134.0</td>\n",
       "      <td>124691.0</td>\n",
       "      <td>14985.0</td>\n",
       "      <td>264.503333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7014.0</td>\n",
       "      <td>7014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>179407.0</td>\n",
       "      <td>31482.0</td>\n",
       "      <td>136257.0</td>\n",
       "      <td>11664.0</td>\n",
       "      <td>319.795000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>177800.0</td>\n",
       "      <td>110382.0</td>\n",
       "      <td>61653.0</td>\n",
       "      <td>5758.0</td>\n",
       "      <td>268.410000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7819.0</td>\n",
       "      <td>7819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168895.0</td>\n",
       "      <td>81360.0</td>\n",
       "      <td>83928.0</td>\n",
       "      <td>3604.0</td>\n",
       "      <td>258.875000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>168067.0</td>\n",
       "      <td>41328.0</td>\n",
       "      <td>121480.0</td>\n",
       "      <td>5253.0</td>\n",
       "      <td>228.045000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8623.0</td>\n",
       "      <td>8623.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>137583.0</td>\n",
       "      <td>61970.0</td>\n",
       "      <td>64196.0</td>\n",
       "      <td>11412.0</td>\n",
       "      <td>272.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>82976.0</td>\n",
       "      <td>44596.0</td>\n",
       "      <td>34365.0</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>265.016667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112542.0</td>\n",
       "      <td>79749.0</td>\n",
       "      <td>30526.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>268.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8983.0</td>\n",
       "      <td>8983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>103713.0</td>\n",
       "      <td>28763.0</td>\n",
       "      <td>67850.0</td>\n",
       "      <td>7095.0</td>\n",
       "      <td>231.285000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3338.0</td>\n",
       "      <td>3338.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>116167.0</td>\n",
       "      <td>56263.0</td>\n",
       "      <td>54072.0</td>\n",
       "      <td>5826.0</td>\n",
       "      <td>262.270000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>103578.0</td>\n",
       "      <td>32245.0</td>\n",
       "      <td>63913.0</td>\n",
       "      <td>7415.0</td>\n",
       "      <td>275.085000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5989.0</td>\n",
       "      <td>5989.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>78514.0</td>\n",
       "      <td>36531.0</td>\n",
       "      <td>37281.0</td>\n",
       "      <td>4697.0</td>\n",
       "      <td>280.870000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7921.0</td>\n",
       "      <td>7921.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>149083.0</td>\n",
       "      <td>67699.0</td>\n",
       "      <td>67367.0</td>\n",
       "      <td>14012.0</td>\n",
       "      <td>238.485000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>186005.0</td>\n",
       "      <td>110878.0</td>\n",
       "      <td>59439.0</td>\n",
       "      <td>15681.0</td>\n",
       "      <td>269.825000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7902.0</td>\n",
       "      <td>7902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>142501.0</td>\n",
       "      <td>57748.0</td>\n",
       "      <td>82187.0</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>263.055000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11523.0</td>\n",
       "      <td>11523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>131417.0</td>\n",
       "      <td>51697.0</td>\n",
       "      <td>72294.0</td>\n",
       "      <td>7424.0</td>\n",
       "      <td>317.550000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9849.0</td>\n",
       "      <td>9849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>219349.0</td>\n",
       "      <td>152598.0</td>\n",
       "      <td>59504.0</td>\n",
       "      <td>7243.0</td>\n",
       "      <td>285.340000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>224205.0</td>\n",
       "      <td>87067.0</td>\n",
       "      <td>127213.0</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>247.325000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9084.0</td>\n",
       "      <td>9084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>135763.0</td>\n",
       "      <td>63499.0</td>\n",
       "      <td>69349.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>217.805000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>170310.0</td>\n",
       "      <td>52792.0</td>\n",
       "      <td>111501.0</td>\n",
       "      <td>6013.0</td>\n",
       "      <td>280.950000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7594.0</td>\n",
       "      <td>7594.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>188143.0</td>\n",
       "      <td>124481.0</td>\n",
       "      <td>48609.0</td>\n",
       "      <td>15048.0</td>\n",
       "      <td>247.233333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5217.0</td>\n",
       "      <td>5217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>155030.0</td>\n",
       "      <td>73761.0</td>\n",
       "      <td>69116.0</td>\n",
       "      <td>12148.0</td>\n",
       "      <td>242.855000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25151.0</td>\n",
       "      <td>25151.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57733.0</td>\n",
       "      <td>19367.0</td>\n",
       "      <td>37288.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>306.590000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>79265.0</td>\n",
       "      <td>23626.0</td>\n",
       "      <td>53810.0</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>281.680000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12086.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77234.0</td>\n",
       "      <td>24308.0</td>\n",
       "      <td>44928.0</td>\n",
       "      <td>7992.0</td>\n",
       "      <td>284.110000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59229.0</td>\n",
       "      <td>23660.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66885.0</td>\n",
       "      <td>12823.0</td>\n",
       "      <td>51374.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>353.785000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>84639.0</td>\n",
       "      <td>30704.0</td>\n",
       "      <td>50047.0</td>\n",
       "      <td>3885.0</td>\n",
       "      <td>240.120000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67427.0</td>\n",
       "      <td>26036.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77339.0</td>\n",
       "      <td>13618.0</td>\n",
       "      <td>62083.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>282.115000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67778.0</td>\n",
       "      <td>14544.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>144967.0</td>\n",
       "      <td>55355.0</td>\n",
       "      <td>70645.0</td>\n",
       "      <td>18963.0</td>\n",
       "      <td>281.335000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>58941.0</td>\n",
       "      <td>16633.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>156630.0</td>\n",
       "      <td>48682.0</td>\n",
       "      <td>103285.0</td>\n",
       "      <td>4659.0</td>\n",
       "      <td>243.683333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15811.0</td>\n",
       "      <td>4846.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>104150.0</td>\n",
       "      <td>26609.0</td>\n",
       "      <td>73844.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>252.592500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71595.0</td>\n",
       "      <td>18291.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>89231.0</td>\n",
       "      <td>35206.0</td>\n",
       "      <td>48795.0</td>\n",
       "      <td>5227.0</td>\n",
       "      <td>305.450000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    firstBlood  firstTower  firstBaron  firstDragon  firstRiftHerald  \\\n",
       "0          0.0         0.0         0.0          0.0              0.0   \n",
       "1          1.0         1.0         0.0          0.0              0.0   \n",
       "2          1.0         0.0         0.0          0.0              0.0   \n",
       "3          0.0         1.0         0.0          0.0              0.0   \n",
       "4          1.0         0.0         0.0          0.0              0.0   \n",
       "5          0.0         1.0         0.0          0.0              0.0   \n",
       "6          0.0         0.0         1.0          1.0              0.0   \n",
       "7          1.0         1.0         0.0          0.0              0.0   \n",
       "8          0.0         0.0         0.0          0.0              0.0   \n",
       "9          1.0         1.0         1.0          1.0              0.0   \n",
       "10         1.0         0.0         0.0          1.0              0.0   \n",
       "11         0.0         1.0         1.0          0.0              0.0   \n",
       "12         1.0         1.0         0.0          0.0              0.0   \n",
       "13         0.0         0.0         0.0          0.0              0.0   \n",
       "14         1.0         1.0         0.0          0.0              0.0   \n",
       "15         0.0         0.0         0.0          0.0              0.0   \n",
       "16         0.0         1.0         0.0          0.0              0.0   \n",
       "17         1.0         0.0         0.0          0.0              0.0   \n",
       "18         1.0         1.0         0.0          1.0              1.0   \n",
       "19         0.0         0.0         1.0          0.0              0.0   \n",
       "20         0.0         1.0         0.0          0.0              0.0   \n",
       "21         1.0         0.0         0.0          0.0              0.0   \n",
       "22         0.0         1.0         0.0          0.0              0.0   \n",
       "23         1.0         0.0         0.0          0.0              0.0   \n",
       "24         0.0         0.0         0.0          0.0              0.0   \n",
       "25         1.0         1.0         0.0          0.0              0.0   \n",
       "26         0.0         0.0         0.0          0.0              0.0   \n",
       "27         1.0         1.0         0.0          0.0              0.0   \n",
       "28         0.0         0.0         0.0          0.0              0.0   \n",
       "29         1.0         1.0         0.0          0.0              0.0   \n",
       "30         1.0         0.0         0.0          0.0              0.0   \n",
       "31         0.0         1.0         0.0          0.0              0.0   \n",
       "32         1.0         1.0         0.0          0.0              0.0   \n",
       "33         0.0         0.0         0.0          0.0              0.0   \n",
       "34         0.0         0.0         0.0          0.0              0.0   \n",
       "35         1.0         1.0         0.0          0.0              0.0   \n",
       "36         0.0         0.0         0.0          0.0              0.0   \n",
       "37         1.0         1.0         0.0          0.0              0.0   \n",
       "38         0.0         1.0         0.0          0.0              0.0   \n",
       "39         1.0         0.0         0.0          0.0              0.0   \n",
       "40         1.0         1.0         0.0          0.0              0.0   \n",
       "41         0.0         0.0         0.0          0.0              0.0   \n",
       "42         0.0         1.0         0.0          0.0              0.0   \n",
       "43         1.0         0.0         0.0          0.0              0.0   \n",
       "44         1.0         0.0         0.0          0.0              0.0   \n",
       "45         0.0         1.0         0.0          0.0              0.0   \n",
       "46         1.0         1.0         0.0          0.0              0.0   \n",
       "47         0.0         0.0         0.0          0.0              0.0   \n",
       "48         0.0         0.0         0.0          1.0              0.0   \n",
       "49         1.0         1.0         0.0          0.0              1.0   \n",
       "50         0.0         0.0         0.0          0.0              0.0   \n",
       "51         1.0         1.0         0.0          1.0              1.0   \n",
       "52         0.0         1.0         0.0          0.0              0.0   \n",
       "53         1.0         0.0         1.0          1.0              1.0   \n",
       "54         0.0         0.0         0.0          1.0              0.0   \n",
       "55         1.0         1.0         1.0          0.0              1.0   \n",
       "\n",
       "    towerKills  inhibitorKills  baronKills  dragonKills  riftHeraldKills  ...  \\\n",
       "0     0.181818        0.333333         0.0          0.0              0.0  ...   \n",
       "1     0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "2     0.363636        1.000000         0.0          0.0              0.0  ...   \n",
       "3     0.272727        0.333333         0.0          0.0              0.0  ...   \n",
       "4     0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "5     0.181818        0.000000         0.0          0.0              0.0  ...   \n",
       "6     0.727273        0.666667         1.0          2.0              0.0  ...   \n",
       "7     0.909091        1.000000         1.0          2.0              0.0  ...   \n",
       "8     0.181818        0.000000         0.0          1.0              0.0  ...   \n",
       "9     1.000000        1.666667         1.0          3.0              0.0  ...   \n",
       "10    0.818182        0.333333         0.0          2.0              0.0  ...   \n",
       "11    0.818182        1.000000         2.0          3.0              0.0  ...   \n",
       "12    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "13    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "14    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "15    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "16    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "17    0.000000        0.000000         0.0          0.0              0.0  ...   \n",
       "18    0.363636        0.000000         0.0          1.0              1.0  ...   \n",
       "19    0.636364        0.000000         2.0          3.0              0.0  ...   \n",
       "20    0.363636        1.000000         0.0          0.0              0.0  ...   \n",
       "21    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "22    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "23    0.181818        0.333333         0.0          0.0              0.0  ...   \n",
       "24    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "25    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "26    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "27    0.363636        1.000000         0.0          0.0              0.0  ...   \n",
       "28    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "29    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "30    0.181818        0.333333         0.0          0.0              0.0  ...   \n",
       "31    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "32    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "33    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "34    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "35    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "36    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "37    0.181818        0.333333         0.0          0.0              0.0  ...   \n",
       "38    0.181818        0.333333         0.0          0.0              0.0  ...   \n",
       "39    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "40    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "41    0.181818        0.666667         0.0          0.0              0.0  ...   \n",
       "42    0.363636        0.666667         0.0          0.0              0.0  ...   \n",
       "43    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "44    0.363636        0.333333         0.0          0.0              0.0  ...   \n",
       "45    0.181818        0.000000         0.0          0.0              0.0  ...   \n",
       "46    0.909091        0.666667         0.0          0.0              0.0  ...   \n",
       "47    0.000000        0.000000         0.0          0.0              0.0  ...   \n",
       "48    0.000000        0.000000         0.0          2.0              0.0  ...   \n",
       "49    0.909091        0.333333         0.0          1.0              1.0  ...   \n",
       "50    0.090909        0.000000         0.0          0.0              0.0  ...   \n",
       "51    1.000000        1.000000         0.0          3.0              1.0  ...   \n",
       "52    0.454545        0.000000         0.0          3.0              0.0  ...   \n",
       "53    0.727273        0.333333         1.0          2.0              0.5  ...   \n",
       "54    0.000000        0.000000         0.0          1.0              0.0  ...   \n",
       "55    0.909091        0.666667         1.0          2.0              1.0  ...   \n",
       "\n",
       "    damageDealtToObjectives  damageDealtToTurrets  visionScore  \\\n",
       "0                    6689.0                6689.0          0.0   \n",
       "1                    3762.0                3762.0          0.0   \n",
       "2                    7822.0                7822.0          0.0   \n",
       "3                    7231.0                7231.0          0.0   \n",
       "4                    7594.0                7594.0          0.0   \n",
       "5                    5217.0                5217.0          0.0   \n",
       "6                   68631.0               30414.0         60.0   \n",
       "7                   94279.0               30962.0        105.0   \n",
       "8                   27439.0               10077.0         57.0   \n",
       "9                   89484.0               37200.0        117.0   \n",
       "10                  90236.0               33923.0         93.0   \n",
       "11                 116608.0               32281.0        142.0   \n",
       "12                   9754.0                9754.0          0.0   \n",
       "13                   2573.0                2573.0          0.0   \n",
       "14                  10201.0               10201.0          0.0   \n",
       "15                  12681.0               12681.0          0.0   \n",
       "16                   9530.0                9530.0          0.0   \n",
       "17                      0.0                   0.0          0.0   \n",
       "18                  51911.0                8670.0        106.0   \n",
       "19                  59135.0               19586.0        162.0   \n",
       "20                   8999.0                8999.0          0.0   \n",
       "21                   2572.0                2572.0          0.0   \n",
       "22                   9782.0                9782.0          0.0   \n",
       "23                   5416.0                5416.0          0.0   \n",
       "24                  10757.0               10757.0          0.0   \n",
       "25                   7014.0                7014.0          0.0   \n",
       "26                   3110.0                3110.0          0.0   \n",
       "27                   7819.0                7819.0          0.0   \n",
       "28                   2603.0                2603.0          0.0   \n",
       "29                   8623.0                8623.0          0.0   \n",
       "30                   4592.0                4592.0          0.0   \n",
       "31                   2983.0                2983.0          0.0   \n",
       "32                   8983.0                8983.0          0.0   \n",
       "33                   3338.0                3338.0          0.0   \n",
       "34                   1451.0                1451.0          0.0   \n",
       "35                   5989.0                5989.0          0.0   \n",
       "36                   7921.0                7921.0          0.0   \n",
       "37                   5790.0                5790.0          0.0   \n",
       "38                   7902.0                7902.0          0.0   \n",
       "39                  11523.0               11523.0          0.0   \n",
       "40                   9849.0                9849.0          0.0   \n",
       "41                   7886.0                7886.0          0.0   \n",
       "42                   9084.0                9084.0          0.0   \n",
       "43                   2401.0                2401.0          0.0   \n",
       "44                   7594.0                7594.0          0.0   \n",
       "45                   5217.0                5217.0          0.0   \n",
       "46                  25151.0               25151.0         19.0   \n",
       "47                      0.0                   0.0          0.0   \n",
       "48                  12086.0                3180.0         62.0   \n",
       "49                  59229.0               23660.0         49.0   \n",
       "50                   4361.0                2590.0         63.0   \n",
       "51                  67427.0               26036.0         84.0   \n",
       "52                  67778.0               14544.0        221.0   \n",
       "53                  58941.0               16633.0        170.0   \n",
       "54                  15811.0                4846.0         87.0   \n",
       "55                  71595.0               18291.0        139.0   \n",
       "\n",
       "    timeCCingOthers  totalDamageTaken  magicalDamageTaken  \\\n",
       "0             118.0           86579.0             16083.0   \n",
       "1              99.0           87404.0             36836.0   \n",
       "2             205.0          228220.0             99974.0   \n",
       "3             189.0          198056.0             57551.0   \n",
       "4             350.0          188143.0            124481.0   \n",
       "5             245.0          155030.0             73761.0   \n",
       "6             121.0          157206.0             99249.0   \n",
       "7             138.0          162145.0             71013.0   \n",
       "8              98.0           85258.0             43306.0   \n",
       "9             148.0          108166.0             30057.0   \n",
       "10            404.0          237405.0            135469.0   \n",
       "11            170.0          287111.0             69924.0   \n",
       "12             85.0           94899.0             47450.0   \n",
       "13            131.0           76870.0             13122.0   \n",
       "14             94.0          161242.0            135728.0   \n",
       "15            148.0          159968.0            105181.0   \n",
       "16             93.0           70754.0             25808.0   \n",
       "17            116.0           90250.0             35184.0   \n",
       "18             81.0          111378.0             45574.0   \n",
       "19             91.0           93089.0             18096.0   \n",
       "20            122.0           99805.0             76944.0   \n",
       "21             94.0          111973.0             51608.0   \n",
       "22            165.0          214156.0             93044.0   \n",
       "23            234.0          177257.0            124601.0   \n",
       "24            205.0          174813.0             35134.0   \n",
       "25             91.0          179407.0             31482.0   \n",
       "26            116.0          177800.0            110382.0   \n",
       "27            168.0          168895.0             81360.0   \n",
       "28            279.0          168067.0             41328.0   \n",
       "29            149.0          137583.0             61970.0   \n",
       "30            170.0           82976.0             44596.0   \n",
       "31            100.0          112542.0             79749.0   \n",
       "32             75.0          103713.0             28763.0   \n",
       "33            123.0          116167.0             56263.0   \n",
       "34            113.0          103578.0             32245.0   \n",
       "35            123.0           78514.0             36531.0   \n",
       "36            175.0          149083.0             67699.0   \n",
       "37            193.0          186005.0            110878.0   \n",
       "38            132.0          142501.0             57748.0   \n",
       "39            199.0          131417.0             51697.0   \n",
       "40            350.0          219349.0            152598.0   \n",
       "41            250.0          224205.0             87067.0   \n",
       "42            106.0          135763.0             63499.0   \n",
       "43            154.0          170310.0             52792.0   \n",
       "44            350.0          188143.0            124481.0   \n",
       "45            245.0          155030.0             73761.0   \n",
       "46             54.0           57733.0             19367.0   \n",
       "47             55.0           79265.0             23626.0   \n",
       "48             82.0           77234.0             24308.0   \n",
       "49             81.0           66885.0             12823.0   \n",
       "50             95.0           84639.0             30704.0   \n",
       "51             92.0           77339.0             13618.0   \n",
       "52            181.0          144967.0             55355.0   \n",
       "53            241.0          156630.0             48682.0   \n",
       "54            114.0          104150.0             26609.0   \n",
       "55            128.0           89231.0             35206.0   \n",
       "\n",
       "    physicalDamageTaken  trueDamageTaken       score  result  \n",
       "0               66466.0           4027.0  328.480000       1  \n",
       "1               37295.0          13268.0  231.865000       0  \n",
       "2              121880.0           6361.0  254.345000       1  \n",
       "3              118924.0          21576.0  247.645000       0  \n",
       "4               48609.0          15048.0  247.233333       1  \n",
       "5               69116.0          12148.0  242.855000       0  \n",
       "6               53627.0           4324.0  263.020000       1  \n",
       "7               86223.0           4903.0  252.873333       0  \n",
       "8               27703.0          14244.0  312.210000       1  \n",
       "9               68603.0           9501.0  272.885000       0  \n",
       "10              81444.0          20488.0  276.070000       1  \n",
       "11             190708.0          26473.0  316.820000       0  \n",
       "12              34028.0          13415.0  254.660000       1  \n",
       "13              57832.0           5911.0  251.110000       0  \n",
       "14              20024.0           5485.0  257.430000       1  \n",
       "15              52795.0           1987.0  280.710000       0  \n",
       "16              38363.0           6578.0  316.825000       1  \n",
       "17              51932.0           3129.0  234.050000       0  \n",
       "18              61803.0           3994.0  349.360000       1  \n",
       "19              66912.0           8074.0  268.496667       0  \n",
       "20              17007.0           5849.0  278.970000       1  \n",
       "21              54423.0           5938.0  245.315000       0  \n",
       "22             103956.0          17151.0  234.945000       1  \n",
       "23              48434.0           4218.0  292.935000       0  \n",
       "24             124691.0          14985.0  264.503333       1  \n",
       "25             136257.0          11664.0  319.795000       0  \n",
       "26              61653.0           5758.0  268.410000       1  \n",
       "27              83928.0           3604.0  258.875000       0  \n",
       "28             121480.0           5253.0  228.045000       1  \n",
       "29              64196.0          11412.0  272.350000       0  \n",
       "30              34365.0           4010.0  265.016667       1  \n",
       "31              30526.0           2263.0  268.500000       0  \n",
       "32              67850.0           7095.0  231.285000       1  \n",
       "33              54072.0           5826.0  262.270000       0  \n",
       "34              63913.0           7415.0  275.085000       1  \n",
       "35              37281.0           4697.0  280.870000       0  \n",
       "36              67367.0          14012.0  238.485000       1  \n",
       "37              59439.0          15681.0  269.825000       0  \n",
       "38              82187.0           2561.0  263.055000       1  \n",
       "39              72294.0           7424.0  317.550000       0  \n",
       "40              59504.0           7243.0  285.340000       1  \n",
       "41             127213.0           9920.0  247.325000       0  \n",
       "42              69349.0           2911.0  217.805000       1  \n",
       "43             111501.0           6013.0  280.950000       0  \n",
       "44              48609.0          15048.0  247.233333       1  \n",
       "45              69116.0          12148.0  242.855000       0  \n",
       "46              37288.0           1075.0  306.590000       1  \n",
       "47              53810.0           1823.0  281.680000       0  \n",
       "48              44928.0           7992.0  284.110000       1  \n",
       "49              51374.0           2682.0  353.785000       0  \n",
       "50              50047.0           3885.0  240.120000       1  \n",
       "51              62083.0           1636.0  282.115000       0  \n",
       "52              70645.0          18963.0  281.335000       1  \n",
       "53             103285.0           4659.0  243.683333       0  \n",
       "54              73844.0           3692.0  252.592500       1  \n",
       "55              48795.0           5227.0  305.450000       0  \n",
       "\n",
       "[56 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"result\"], axis = 1)\n",
    "y = df.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_feat = [\n",
    "    \"firstBlood\",\n",
    "    \"firstTower\",\n",
    "    \"firstBaron\",\n",
    "    \"firstDragon\",\n",
    "    \"firstDragon\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "log_feat = ['towerKills', 'inhibitorKills', 'baronKills',\n",
    "       'dragonKills', 'riftHeraldKills', 'kills', 'deaths', 'assists',\n",
    "       'totalDamageDealt', 'magicDamageDealt', 'physicalDamageDealt',\n",
    "       'totalDamageDealtToChampions', 'magicDamageDealtToChampions',\n",
    "       'physicalDamageDealtToChampions', 'trueDamageDealtToChampions',\n",
    "       'goldEarned', 'champLevel', 'totalMinionsKilled', 'largestMultiKill',\n",
    "       'killingSprees', 'doubleKills', 'tripleKills', 'quadraKills',\n",
    "       'pentaKills', 'longestTimeSpentLiving', 'totalHeal',\n",
    "       'damageDealtToObjectives', 'damageDealtToTurrets', 'visionScore',\n",
    "       'timeCCingOthers', 'totalDamageTaken', 'magicalDamageTaken',\n",
    "       'physicalDamageTaken', 'trueDamageTaken', 'score']\n",
    "log_tranformer = Pipeline(steps = [\n",
    "    (\"log\", FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat), \n",
    "                                            (\"log\", log_tranformer, log_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"logistic\", LogisticRegression(random_state=0))])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "5     0\n",
       "33    0\n",
       "13    0\n",
       "19    0\n",
       "50    1\n",
       "36    1\n",
       "26    1\n",
       "44    1\n",
       "12    1\n",
       "54    1\n",
       "3     0\n",
       "Name: result, dtype: int32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that the model is not accurate enough to predict the result of the game. Hence we dive deeper into the preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Refine the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we developed our model, Riot Api didn't give us the optimal data. Instead, we choose to use the data parsed by previous users on kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset names:\n",
    "Challenger_Ranked_Games.csv\n",
    "GrandMaster_Ranked_Games.csv\n",
    "high_diamond_ranked_10min.csv\n",
    "\n",
    "source: kaggle.com/gyejr95/league-of-legends-challenger-ranked-games2020?fbclid=IwAR3Mo5lKWOWSEUSFJWHQ_Gn45opGB5GI_5LJoWpiRISw3OdFXEFCbiTpYLU\n",
    "\n",
    "description:\n",
    "The matches of high-ranked players. Includes columns containing similar information to the previous DataFrame parsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26904"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(challenger_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gameId', 'gameDuraton', 'blueWins', 'blueFirstBlood', 'blueFirstTower',\n",
       "       'blueFirstBaron', 'blueFirstDragon', 'blueFirstInhibitor',\n",
       "       'blueDragonKills', 'blueBaronKills', 'blueTowerKills',\n",
       "       'blueInhibitorKills', 'blueWardPlaced', 'blueWardkills', 'blueKills',\n",
       "       'blueDeath', 'blueAssist', 'blueChampionDamageDealt', 'blueTotalGold',\n",
       "       'blueTotalMinionKills', 'blueTotalLevel', 'blueAvgLevel',\n",
       "       'blueJungleMinionKills', 'blueKillingSpree', 'blueTotalHeal',\n",
       "       'blueObjectDamageDealt', 'redWins', 'redFirstBlood', 'redFirstTower',\n",
       "       'redFirstBaron', 'redFirstDragon', 'redFirstInhibitor',\n",
       "       'redDragonKills', 'redBaronKills', 'redTowerKills', 'redInhibitorKills',\n",
       "       'redWardPlaced', 'redWardkills', 'redKills', 'redDeath', 'redAssist',\n",
       "       'redChampionDamageDealt', 'redTotalGold', 'redTotalMinionKills',\n",
       "       'redTotalLevel', 'redAvgLevel', 'redJungleMinionKills',\n",
       "       'redKillingSpree', 'redTotalHeal', 'redObjectDamageDealt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenger_games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65896"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grandmaster_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gameId', 'gameDuraton', 'blueWins', 'blueFirstBlood', 'blueFirstTower',\n",
       "       'blueFirstBaron', 'blueFirstDragon', 'blueFirstInhibitor',\n",
       "       'blueDragonKills', 'blueBaronKills', 'blueTowerKills',\n",
       "       'blueInhibitorKills', 'blueWardPlaced', 'blueWardkills', 'blueKills',\n",
       "       'blueDeath', 'blueAssist', 'blueChampionDamageDealt', 'blueTotalGold',\n",
       "       'blueTotalMinionKills', 'blueTotalLevel', 'blueAvgLevel',\n",
       "       'blueJungleMinionKills', 'blueKillingSpree', 'blueTotalHeal',\n",
       "       'blueObjectDamageDealt', 'redWins', 'redFirstBlood', 'redFirstTower',\n",
       "       'redFirstBaron', 'redFirstDragon', 'redFirstInhibitor',\n",
       "       'redDragonKills', 'redBaronKills', 'redTowerKills', 'redInhibitorKills',\n",
       "       'redWardPlaced', 'redWardkills', 'redKills', 'redDeath', 'redAssist',\n",
       "       'redChampionDamageDealt', 'redTotalGold', 'redTotalMinionKills',\n",
       "       'redTotalLevel', 'redAvgLevel', 'redJungleMinionKills',\n",
       "       'redKillingSpree', 'redTotalHeal', 'redObjectDamageDealt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grandmaster_games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gameId', 'gameDuraton', 'blueWins', 'blueFirstBlood', 'blueFirstTower',\n",
       "       'blueFirstBaron', 'blueFirstDragon', 'blueFirstInhibitor',\n",
       "       'blueDragonKills', 'blueBaronKills', 'blueTowerKills',\n",
       "       'blueInhibitorKills', 'blueWardPlaced', 'blueWardkills', 'blueKills',\n",
       "       'blueDeath', 'blueAssist', 'blueChampionDamageDealt', 'blueTotalGold',\n",
       "       'blueTotalMinionKills', 'blueTotalLevel', 'blueAvgLevel',\n",
       "       'blueJungleMinionKills', 'blueKillingSpree', 'blueTotalHeal',\n",
       "       'blueObjectDamageDealt', 'redWins', 'redFirstBlood', 'redFirstTower',\n",
       "       'redFirstBaron', 'redFirstDragon', 'redFirstInhibitor',\n",
       "       'redDragonKills', 'redBaronKills', 'redTowerKills', 'redInhibitorKills',\n",
       "       'redWardPlaced', 'redWardkills', 'redKills', 'redDeath', 'redAssist',\n",
       "       'redChampionDamageDealt', 'redTotalGold', 'redTotalMinionKills',\n",
       "       'redTotalLevel', 'redAvgLevel', 'redJungleMinionKills',\n",
       "       'redKillingSpree', 'redTotalHeal', 'redObjectDamageDealt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " master_games.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_minute(raw_df):\n",
    "    properties = [\"WardPlaced\", \n",
    "                  \"Wardkills\", \n",
    "                  \"Kills\", \n",
    "                  \"ChampionDamageDealt\", \n",
    "                  \"TotalGold\", \n",
    "                  \"TotalMinionKills\", \n",
    "                  \"JungleMinionKills\",\n",
    "                  \"TotalHeal\", \n",
    "                  \"ObjectDamageDealt\"]\n",
    "    raw_df[\"duration\"] = raw_df[\"duration\"] / 60\n",
    "    game_duration = raw_df[\"duration\"]\n",
    "    for column in properties:\n",
    "        raw_df[column] = raw_df[column] / game_duration\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(blue_df, red_df):\n",
    "    properties = [\"WardPlaced\", \n",
    "                  \"Wardkills\", \n",
    "                  \"Kills\", \n",
    "                  \"ChampionDamageDealt\", \n",
    "                  \"TotalGold\", \n",
    "                  \"TotalMinionKills\",\n",
    "                  \"JungleMinionKills\",\n",
    "                  \"TotalHeal\",\n",
    "                  \"ObjectDamageDealt\"]\n",
    "    for column in properties:\n",
    "        blue_columns_values = []\n",
    "        red_columns_values = []\n",
    "        for index, row in blue_df.iterrows():\n",
    "            blue_columns_values.append(blue_df.loc[index][column] - red_df.loc[index][column])\n",
    "            red_columns_values.append(red_df.loc[index][column] - blue_df.loc[index][column])\n",
    "        blue_df[column] = blue_columns_values\n",
    "        red_df[column] = red_columns_values\n",
    "        blue_columns_values = []\n",
    "        red_columns_values = []        \n",
    "    return([blue_df, red_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(raw_df):\n",
    "    column_list = []\n",
    "    blue_df = raw_df.loc[:, raw_df.columns.str.startswith('blue')]\n",
    "    for column in blue_df.columns:\n",
    "        column_list.append(column[4:])\n",
    "    \n",
    "    blue_df.columns = column_list\n",
    "    blue_df[\"duration\"] = raw_df.get(\"gameDuraton\")\n",
    "    blue_df[\"team\"] = \"b\"\n",
    "    blue_df = per_minute(blue_df)\n",
    "    \n",
    "    column_list = []\n",
    "    red_df = raw_df.loc[:, raw_df.columns.str.startswith('red')]\n",
    "    for column in red_df.columns:\n",
    "        column_list.append(column[3:])\n",
    "    \n",
    "    red_df.columns = column_list\n",
    "    red_df[\"duration\"]  = raw_df.get(\"gameDuraton\")\n",
    "    red_df[\"team\"] = \"r\"\n",
    "    red_df = per_minute(red_df)\n",
    "    \n",
    "    [blue_df, red_df] = difference(blue_df, red_df)\n",
    "    \n",
    "    complete_df = blue_df.append(red_df)\n",
    "    complete_df = complete_df.drop(columns = [\"TotalLevel\"])\n",
    "    complete_df[\"AvgLevel\"] = complete_df[\"AvgLevel\"] / 18\n",
    "    complete_df[\"TowerKills\"] = complete_df[\"TowerKills\"] / 11\n",
    "    complete_df = complete_df.reset_index()\n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We run our model based upon the previous 5000 instances of three tables accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "challenger_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the challenger model is 0.986\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(challenger_games[:5000])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "    \"FirstBlood\",\n",
    "    \"FirstTower\",\n",
    "    \"FirstBaron\",\n",
    "    \"FirstDragon\",\n",
    "    \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "log_feat = ['DragonKills', 'BaronKills',\n",
    "       'TowerKills', 'InhibitorKills', 'WardPlaced', 'Wardkills', 'Kills',\n",
    "       'Death', 'Assist', 'ChampionDamageDealt', 'TotalGold',\n",
    "       'TotalMinionKills', 'AvgLevel', 'JungleMinionKills', 'KillingSpree',\n",
    "       'TotalHeal', 'ObjectDamageDealt', 'duration']\n",
    "log_tranformer = Pipeline(steps = [\n",
    "    (\"log\", FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat), \n",
    "                                            (\"log\", log_tranformer, log_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the challenger model is\", accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grandmaster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the grandmaster model is 0.988\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(grandmaster_games[:5000])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "    \"FirstBlood\",\n",
    "    \"FirstTower\",\n",
    "    \"FirstBaron\",\n",
    "    \"FirstDragon\",\n",
    "    \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "log_feat = ['DragonKills', 'BaronKills',\n",
    "       'TowerKills', 'InhibitorKills', 'WardPlaced', 'Wardkills', 'Kills',\n",
    "       'Death', 'Assist', 'ChampionDamageDealt', 'TotalGold',\n",
    "       'TotalMinionKills', 'AvgLevel', 'JungleMinionKills', 'KillingSpree',\n",
    "       'TotalHeal', 'ObjectDamageDealt', 'duration']\n",
    "log_tranformer = Pipeline(steps = [\n",
    "    (\"log\", FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat), \n",
    "                                            (\"log\", log_tranformer, log_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the grandmaster model is\", accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "master_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the master model is 0.993\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(master_games[:5000])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "    \"FirstBlood\",\n",
    "    \"FirstTower\",\n",
    "    \"FirstBaron\",\n",
    "    \"FirstDragon\",\n",
    "    \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "log_feat = ['DragonKills', 'BaronKills',\n",
    "       'TowerKills', 'InhibitorKills', 'WardPlaced', 'Wardkills', 'Kills',\n",
    "       'Death', 'Assist', 'ChampionDamageDealt', 'TotalGold',\n",
    "       'TotalMinionKills', 'AvgLevel', 'JungleMinionKills', 'KillingSpree',\n",
    "       'TotalHeal', 'ObjectDamageDealt', 'duration']\n",
    "log_tranformer = Pipeline(steps = [\n",
    "    (\"log\", FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat), \n",
    "                                            (\"log\", log_tranformer, log_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the master model is\", accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Important Features (using challenger dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the firstBlood model is 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(challenger_games[:500])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "    \"FirstBlood\",\n",
    "#     \"FirstTower\",\n",
    "#     \"FirstBaron\",\n",
    "#     \"FirstDragon\",\n",
    "#     \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the firstBlood model is\", accuracy_score(preds, y_test))\n",
    "a = [\"first blood\", accuracy_score(preds, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the firstTower model is 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(challenger_games[:500])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "#     \"FirstBlood\",\n",
    "    \"FirstTower\",\n",
    "#     \"FirstBaron\",\n",
    "#     \"FirstDragon\",\n",
    "#     \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the firstTower model is\", accuracy_score(preds, y_test))\n",
    "b = [\"first tower\", accuracy_score(preds, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the firstBaron model is 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(challenger_games[:500])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "#     \"FirstBlood\",\n",
    "#     \"FirstTower\",\n",
    "    \"FirstBaron\",\n",
    "#     \"FirstDragon\",\n",
    "#     \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the firstBaron model is\", accuracy_score(preds, y_test))\n",
    "c = [\"first baron\", accuracy_score(preds, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the firstDragon model is 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(challenger_games[:500])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "#     \"FirstBlood\",\n",
    "#     \"FirstTower\",\n",
    "#     \"FirstBaron\",\n",
    "    \"FirstDragon\",\n",
    "#     \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the firstDragon model is\", accuracy_score(preds, y_test))\n",
    "d = [\"first dragon\", accuracy_score(preds, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the firstInhibitor model is 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(challenger_games[:500])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_feat = [\n",
    "#     \"FirstBlood\",\n",
    "#     \"FirstTower\",\n",
    "#     \"FirstBaron\",\n",
    "#     \"FirstDragon\",\n",
    "    \"FirstInhibitor\"\n",
    "]\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the firstInhibitor model is\", accuracy_score(preds, y_test))\n",
    "e = [\"first inhibitor\", accuracy_score(preds, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy of Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first blood</th>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first tower</th>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first baron</th>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first dragon</th>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first inhibitor</th>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy of Model\n",
       "Feature Name                      \n",
       "first blood                  0.660\n",
       "first tower                  0.695\n",
       "first baron                  0.700\n",
       "first dragon                 0.630\n",
       "first inhibitor              0.805"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance = pd.DataFrame([a, b, c, d, e]).rename({0: \"Feature Name\", 1: \"Accuracy of Model\"}, axis = 1).set_index(\"Feature Name\")\n",
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eb48614f08>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance.plot(kind = \"bar\", figsize=(20, 5), title = \"The Relevance of Categorical Features to the Result of the Game of the Predictive Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the master model is 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "output = preprocessing(master_games[:500])\n",
    "\n",
    "X = output.drop([\"Wins\"], axis = 1)\n",
    "y = output.Wins\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cat_transformer = Pipeline(steps = [\n",
    "    (\"onehot\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "log_feat = ['DragonKills', 'BaronKills',\n",
    "       'TowerKills', 'InhibitorKills', 'WardPlaced', 'Wardkills', 'Kills',\n",
    "       'Death', 'Assist', 'ChampionDamageDealt', 'TotalGold',\n",
    "       'TotalMinionKills', 'AvgLevel', 'JungleMinionKills', 'KillingSpree',\n",
    "       'TotalHeal', 'ObjectDamageDealt', 'duration']\n",
    "log_tranformer = Pipeline(steps = [\n",
    "    (\"log\", FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(transformers = [(\"cat\", cat_transformer, cat_feat), \n",
    "                                            (\"log\", log_tranformer, log_feat)])\n",
    "\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "preds = pl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the master model is\", accuracy_score(preds, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_tranformer = Pipeline(steps = [\n",
    "    (\"log\", FunctionTransformer(lambda x: x))\n",
    "])\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(log_feat)):\n",
    "    preproc = ColumnTransformer(transformers = [(\"log\", log_tranformer, [log_feat[i]])])\n",
    "    pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"xgbclassifier\", xgb.XGBClassifier())])\n",
    "    pl.fit(X_train, y_train)\n",
    "    preds = pl.predict(X_test)\n",
    "    result.append([log_feat[i], accuracy_score(preds, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eb552ec308>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(result).rename({0: \"Numeric Feature Name\", 1: \"Accuracy of Model\"}, axis = 1).sort_values(by = \"Accuracy of Model\", ascending = False)\\\n",
    ".set_index(\"Numeric Feature Name\")\\\n",
    ".plot(kind = \"bar\", figsize=(20, 5), title = \"The Relevance of Numeric Features to the Result of the Game of the Predictive Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gameId', 'gameDuraton', 'blueWins', 'blueFirstBlood', 'blueFirstTower',\n",
       "       'blueFirstBaron', 'blueFirstDragon', 'blueFirstInhibitor',\n",
       "       'blueDragonKills', 'blueBaronKills', 'blueTowerKills',\n",
       "       'blueInhibitorKills', 'blueWardPlaced', 'blueWardkills', 'blueKills',\n",
       "       'blueDeath', 'blueAssist', 'blueChampionDamageDealt', 'blueTotalGold',\n",
       "       'blueTotalMinionKills', 'blueTotalLevel', 'blueAvgLevel',\n",
       "       'blueJungleMinionKills', 'blueKillingSpree', 'blueTotalHeal',\n",
       "       'blueObjectDamageDealt', 'redWins', 'redFirstBlood', 'redFirstTower',\n",
       "       'redFirstBaron', 'redFirstDragon', 'redFirstInhibitor',\n",
       "       'redDragonKills', 'redBaronKills', 'redTowerKills', 'redInhibitorKills',\n",
       "       'redWardPlaced', 'redWardkills', 'redKills', 'redDeath', 'redAssist',\n",
       "       'redChampionDamageDealt', 'redTotalGold', 'redTotalMinionKills',\n",
       "       'redTotalLevel', 'redAvgLevel', 'redJungleMinionKills',\n",
       "       'redKillingSpree', 'redTotalHeal', 'redObjectDamageDealt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_games.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "In the baseline model, we proposed to use the logistic regression to classify the result of matches. We chose this model to predict because logistic regression predicts the categorical results, which is exactly what we needed. However, to further amplify our model, we utilize the XGboost classifier in the refined model to increase the accuracy of our model, because boosted trees can largely increase the prediction power. Since the original dataset has comprehensive features on what we are looking for (the important factors that can determine the result of the games), we basically normalize the data with the duration of each game. This feature of engineering is proven to be effective. To find the best features that have a high correlation to the result of the game, we devised EDA to analyze the features and tried to find the correlation between the features. For example, damage dealt with champions can be a strong factor determining the result of the games, but other features like first blood, first baron, and a number of dragons killed may have a high correlation to total damage. In terms of optimization, our model has done a great improvement from the baseline model to the improved model, with accuracy increasing from around 70% to nearly 98%. We had to admit that the task is simple given that the statistics after the match can easily show the result of the match, but the significance of the optimization is that some of the features being engineered to do play an important role in determining the result of the game. For example, after finishing the normalization, ObjectDamageDealt doesn't affect the accuracy of the model that much.\n",
    "\n",
    "Before successfully setting up the model, we encountered some problems with implementation. The first one we encountered is dataset availability. Riot API has some strict rules against the individual developers so that at first we were only able to develop the baseline model based upon a limited amount of instances. By comprehensive EDA on the dataset, we figured that there is no need for us to parse instances every time we opened the notebook, so we decided to broaden the number of features by utilizing the dataset available on Kaggle. The other problem we met is how to evaluate the champion combination for each side. The huge challenge of League of Legends champion combinations is that the strength is not static with time. Some may pose a great threat against the enemy team at the very early stage of the game, while others dominate the game later. In other words, the scale is astonishingly different. Times series analyses of champion strength can be a good approach to address this problem, but it's hard to quantify the champion skills. Hence, we cited metasrc.com's champion tier list, which contains the subjective score for each champion based upon \"win rate, ban rate, pick rate, and KDA.\" In other words, we avoided this problem by going the other way around.\n",
    "\n",
    "In our demo, we tried to present an interactive demo of how we can calculate the result of the game based on the objectives being taken down by each team. This can a prospective application of the model we develop. Choose the statistics in the drop down bar, can the result can be calculated and presented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shows the relevance and importance of the game statistics to the result of each match. From the baseline model to the refined model, the accuracy improves from 0.66 to over 0.98. The gap is significant in that the model basically produces the accurate results for near every instances.\n",
    "\n",
    "Here are the interesting findings we delve out of the model. With the refined model being able to predict the final result, we conditionally eliminate some of the features to see if there are some features that can outperform others. For example, the most important objective, for the players should be the first inhibitor, which is a late game objective in LoL. At the same time, the most accurate single numeric feature is the total gold difference for each match. One recommendation I can give for the professional LoL teams is try as hard as they can to compete the other team on the golden.\n",
    "\n",
    "However, there are some potential dangers of our model. The champion scores calculated based on matasrc.com \\cite{metasrc} may vary from patch to patch. Therefore, the model should constantly refresh its database of champion scores. \n",
    "\n",
    "Given the consistency of our model based on the available dataset, we deem it to be useful in analyze the games in professional LoL arena. With no special attention to the hyperparameter, the model is trained for finding the special feature that can should be prioritized for the team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There have been some literature that study win prediction using machine learning algorithms. Different methods have been implemented for feature extraction. There are papers that used simpler metric that records the presence of champions on both teams or comprehensive metrics that further dissected a match into features like champion attributes and post-game statistics for further analysis. In both papers mentioned above, different machine learning models are also Utilised. For they have used an augmented logistic regression that obtained a F1 Score pf 0.781. In another paper, they used classifiers like random forest and Support Vector Machine (SVM) for the model, obtaining a F1 score of 0.641 with their feature extractions techniques. Comparing across existing literature, we can see that our model has a more accurate performance, this might be due to the more mature machine learning we used and we did not utilise specific champion statistics in our data set. The major novelty of our work is that we studied this data set using a state-of-the-art machine learning classifier and analyses importance of respective factors towards the success of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
